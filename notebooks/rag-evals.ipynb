{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# sys imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import nest_asyncio\n",
    "\n",
    "# data handling\n",
    "import pandas as pd\n",
    "\n",
    "# RAG\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Response\n",
    ")\n",
    "from llama_index.core.evaluation import (\n",
    "    BatchEvalRunner,\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    "    RetrieverEvaluator,\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    "    DatasetGenerator\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "nest_asyncio.apply()\n",
    "sys.path.append(os.path.join('/Users/juandiegogallegoquiceno/Desktop/pinacle/secrets'))\n",
    "\n",
    "# import secrets\n",
    "from hf_secrets import api_token as hf_token\n",
    "from openai_secrets import api_key as oai_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign as environ vars\n",
    "os.environ['OPENAI_API_KEY'] = oai_token\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 1/1 [00:00<00:00,  1.32file/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = SimpleDirectoryReader('../data')\n",
    "documents = reader.load_data('Final Policy document_LICs New Jeevan Shanti_V05_logo.pdf')\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load embed model\n",
    "hf_embed_model = HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.01s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING:llama_index.llms.huggingface.base:The model `meta-llama/Llama-2-7b-hf` and tokenizer `StabilityAI/stablelm-tuned-alpha-3b` are different, please ensure that they are compatible.\n"
     ]
    }
   ],
   "source": [
    "gpt3_5 = OpenAI(model='gpt-3.5-turbo', temperature=0.1)\n",
    "llama2 = HuggingFaceLLM(\n",
    "    model_name=\"meta-llama/Llama-2-7b-hf\",\n",
    "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/llama_index/core/evaluation/dataset_generation.py:213: DeprecationWarning: Call to deprecated class DatasetGenerator. (Deprecated in favor of `RagDatasetGenerator` which should be used instead.)\n",
      "  return cls(\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2550292180345871 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59878, Requested 1074. Please try again in 952ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.4493796086750399 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 60001, Requested 1073. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.04894390416207228 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59873, Requested 1055. Please try again in 928ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.061282583289993364 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59887, Requested 1063. Please try again in 950ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.14051871139939542 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59893, Requested 1052. Please try again in 945ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.36330911793458576 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59831, Requested 1065. Please try again in 896ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8148553681773635 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59863, Requested 1070. Please try again in 933ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.0469174605666522 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59798, Requested 1052. Please try again in 850ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.44251661450302016 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59797, Requested 1065. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.9963489859499701 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59770, Requested 1074. Please try again in 844ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.392914068846633 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59733, Requested 1073. Please try again in 806ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 2.0005545569760157 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59861, Requested 1073. Please try again in 934ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.9340145884591528 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59855, Requested 996. Please try again in 851ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8525232980975063 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59853, Requested 1002. Please try again in 855ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.669313555686288 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59840, Requested 994. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6373736988166906 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59832, Requested 989. Please try again in 821ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.30068452919446786 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59850, Requested 988. Please try again in 838ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.3134981329421713 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-zF3FZaYpeFVIivGN1UH5GiOz on tokens per min (TPM): Limit 60000, Used 59860, Requested 989. Please try again in 849ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/llama_index/core/evaluation/dataset_generation.py:310: DeprecationWarning: Call to deprecated class QueryResponseDataset. (Deprecated in favor of `LabelledRagDataset` which should be used instead.)\n",
      "  return QueryResponseDataset(queries=queries, responses=responses_dict)\n"
     ]
    }
   ],
   "source": [
    "# generate some data from document\n",
    "num_eval_nodes = 10\n",
    "data_generator = DatasetGenerator.from_documents(documents, llm=gpt3_5)\n",
    "eval_dataset = data_generator.generate_dataset_from_nodes(num=num_eval_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "What is the registration number of LIC's New Jeevan Shanti policy? The registration number of LIC's New Jeevan Shanti policy is 512.\n"
     ]
    }
   ],
   "source": [
    "# now get eval questions and eval answers\n",
    "eval_questions = [ex[0] for ex in eval_dataset.qr_pairs]\n",
    "eval_answers = [ex[1] for ex in eval_dataset.qr_pairs]\n",
    "\n",
    "print(len(eval_questions))\n",
    "print(eval_questions[0], eval_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and eval query example\n",
    "eval_query = eval_questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Hugginface Embedding BAAI/bge-small-en-v1.5\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=hf_embed_model, llm=gpt3_5)\n",
    "# query engine to generate response\n",
    "query_engine = index.as_query_engine()\n",
    "# define retriever as well\n",
    "retriever = index.as_retriever(similarity_top_k=3)\n",
    "# get nodes\n",
    "nodes = retriever.retrieve(eval_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to get metric result from batch eval runner\n",
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[f'{key}']\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result.passing:\n",
    "            correct += 1\n",
    "    score = correct / len(results)\n",
    "    print(f\"{key} Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a runner evaluation instance\n",
    "runner = BatchEvalRunner(\n",
    "    {\n",
    "        \"faithfulness\": FaithfulnessEvaluator(llm=gpt3_5),\n",
    "        \"relevancy\": RelevancyEvaluator(llm=gpt3_5),\n",
    "        \"correctness\": CorrectnessEvaluator(llm=gpt3_5)\n",
    "    },\n",
    "    workers=8\n",
    ")\n",
    "# evaluate\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine,\n",
    "    queries=eval_questions,\n",
    "    reference=eval_answers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness Score: 0.8\n",
      "relevancy Score: 0.6\n",
      "correctness Score: 0.4\n"
     ]
    }
   ],
   "source": [
    "# see results\n",
    "for key in [\"faithfulness\", \"relevancy\", \"correctness\"]:\n",
    "    get_eval_results(key, eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that LLM is not hallucinating but answers has not an optimum quality based on correctnes score and are not the most relevant for the passed query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Llama2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Hugginface Embedding BAAI/bge-small-en-v1.5\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=hf_embed_model, llm=llama2)\n",
    "# query engine to generate response\n",
    "query_engine = index.as_query_engine()\n",
    "# define retriever as well\n",
    "retriever = index.as_retriever(similarity_top_k=3)\n",
    "# get nodes\n",
    "nodes = retriever.retrieve(eval_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/llamaindex/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define a runner evaluation instance\n",
    "runner = BatchEvalRunner(\n",
    "    {\n",
    "        \"faithfulness\": FaithfulnessEvaluator(llm=llama2),\n",
    "        \"relevancy\": RelevancyEvaluator(llm=llama2),\n",
    "        \"correctness\": CorrectnessEvaluator(llm=llama2)\n",
    "    },\n",
    "    workers=8\n",
    ")\n",
    "# evaluate\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine,\n",
    "    queries=eval_questions,\n",
    "    reference=eval_answers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness Score: 0.8\n",
      "relevancy Score: 0.6\n",
      "correctness Score: 0.4\n"
     ]
    }
   ],
   "source": [
    "# see results\n",
    "for key in [\"faithfulness\", \"relevancy\", \"correctness\"]:\n",
    "    get_eval_results(key, eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
